{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Train_network-susan.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPaXzWjopQN898uNGryM40n"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0aN3zYTc1fvr","executionInfo":{"status":"ok","timestamp":1623846905829,"user_tz":-120,"elapsed":25839,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"}},"outputId":"37c17089-f4f9-4f57-dd59-96718abca153"},"source":["\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nRugKdhyyjmv","executionInfo":{"status":"ok","timestamp":1623846911742,"user_tz":-120,"elapsed":5930,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"}},"outputId":"6d0488b3-2547-4097-faea-67a03539e3aa"},"source":["# check model from the paper: https://github.com/zhengxu001/neural-data-augmentation\n","\n","!pip install config\n","import os\n","import scipy.io\n","import scipy.misc\n","import numpy as np\n","import argparse\n","from keras.layers import Dense\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg19 import VGG19\n","from keras.models import Model\n","from keras.optimizers import SGD\n","from keras.utils import np_utils\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import TensorBoard\n","import shutil\n","import itertools\n","import tensorflow as tf\n","import config\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting config\n","  Downloading https://files.pythonhosted.org/packages/67/af/a7c8be986afee4cf277045cfdb06605296ff3f1a1de415d62c18a7a33040/config-0.5.0.post0-py2.py3-none-any.whl\n","Installing collected packages: config\n","Successfully installed config-0.5.0.post0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zG3UUWmhTqQ2","executionInfo":{"status":"ok","timestamp":1623846911745,"user_tz":-120,"elapsed":8,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"}}},"source":["path = \"/content/gdrive/MyDrive/CV-DL/\"\n","def rename_Styles():\n","    data_path = path + \"Styletransfer_results_2/\"\n","    categories = os.listdir(data_path)\n","    print(categories)\n","    for cat in categories:\n","        data = data_path + str(cat) + \"/\"\n","        image_files = os.listdir(os.path.join(data_path, cat))\n","        # print(image_files)\n","        for file in image_files:\n","          old_name = file\n","          file =file.split(\".\")\n","          new_name = file[0] + \"_style_2.\" + file[1]\n","\n","          src = data+old_name\n","          dest = data+new_name\n","          os.rename(src, dest) \n","          # print(src, dest)\n","\n","# rename_Styles()\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qx94i7CSrUG_","executionInfo":{"status":"ok","timestamp":1623846911746,"user_tz":-120,"elapsed":6,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"}}},"source":["path = \"/content/gdrive/MyDrive/CV-DL/\"\n","\n","import os\n","import shutil\n","import itertools\n","import numpy as np\n","import config\n","import argparse\n","\n","def split_dataset():\n","    data_path = path + \"101_ObjectCategories/\"\n","    test_path = path + \"101_ObjectCategories_test/\"\n","    categories = os.listdir(data_path)\n","    print(categories)\n","    for cat in categories:\n","        image_files = os.listdir(os.path.join(data_path, cat))\n","        choices = np.random.choice([0, 1], size=(len(image_files),), p=[0.70, .30])\n","        files_to_move = itertools.compress(image_files, choices)\n","        \n","        for _f in files_to_move:\n","            print(_f)\n","            origin_path = os.path.join(data_path, cat, _f)\n","            dest_dir = os.path.join(test_path, cat)\n","            dest_path = os.path.join(test_path, cat, _f)\n","            if not os.path.isdir(dest_dir):\n","                os.makedirs(dest_dir)\n","            shutil.move(origin_path, dest_path)\n","\n","#only do this to make the test dataset, commented out for now\n","# split_dataset()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGBX5SRi3AVG","executionInfo":{"status":"ok","timestamp":1623846911746,"user_tz":-120,"elapsed":5,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"}}},"source":["\n","\n","def augmentation():\n","        train_datagen = ImageDataGenerator(\n","            rescale=1. / 255)\n","        val_datagen = ImageDataGenerator(\n","            rescale=1. / 255)\n","        return train_datagen, val_datagen\n","\n","def get_datasets(train_path, test_path):        \n","        train_dataset = path + train_path\n","        validation_dataset = path + test_path\n","        class_number = 12\n","        return train_dataset, validation_dataset, class_number\n","\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ftYXs1_1EEx","outputId":"ed9cb148-6496-43e2-a8a7-dd546a74a0b4"},"source":["#datapaths to both datasets\n","data_dir_stylized_1 =   \"/Styletransfer_results_1/\"\n","data_dir_stylized_2 =   \"/Styletransfer_results_2/\"\n","data_dir_stylized_3 =   \"/Styletransfer_results_3/\"\n","data_dir_stylized_4 =   \"/Styletransfer_results_all/\"\n","data_path_1 =  \"12_ObjectCategories/\"\n","data_path_2 =  \"101_ObjectCategories/\"\n","data_dir_aug = \"/5_augmentations_style_all/\"\n","\n","#fill this in!!!!\n","train_path = data_dir_aug\n","\n","test_path=  \"12_ObjectCategories_test/\"\n","\n","\n","#for saving checkpoints\n","checkpoint_path = path + \"models/cp.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","aug_strategy=\"NA\"\n","model = 'vgg16'\n","dataset = \"caltech101\"\n","num_epochs = 70\n","style =\"NA\" \n","\n","\n","\n","def build_vgg_models(model, dataset, epochs, aug_strategy, train_path, test_path):\n","    print(\"User Model\", model)\n","    print(\"Expected Epochs is\", epochs)\n","\n","    train_dataset, validation_dataset, class_number = get_datasets(train_path, test_path)\n","      \n","    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n","\n","    tbCallBack = TensorBoard(log_dir= \"logs\", histogram_freq=0, write_graph=True, write_images=True)\n","\n","    #saves weights\n","    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n","                                                 save_weights_only=True,\n","                                                 verbose=1)\n","    vgg = eval(model)(weights='imagenet')\n","    fc2 = vgg.get_layer('fc2').output\n","    prediction = Dense(units=class_number, activation='softmax', name='logit')(fc2)\n","    model = Model(vgg.input, prediction)\n","    model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.0001), metrics=['accuracy'])\n","\n","    model.summary()\n","    #only for normal augmentations for now\n","    train_datagen, val_datagen = augmentation()\n","      \n","    train_generator = train_datagen.flow_from_directory(\n","          train_dataset,\n","          target_size=(224,224),\n","          batch_size=32,\n","          class_mode='categorical')\n","    val_generator = train_datagen.flow_from_directory(\n","          validation_dataset,\n","          target_size=(224,224),\n","          batch_size=32,\n","          shuffle=False, \n","          class_mode='categorical')\n","\n","    model.fit(train_generator, validation_data=val_generator,\n","          epochs=epochs, steps_per_epoch = None, callbacks=[earlyStopping, tbCallBack])\n","\n","build_vgg_models(model.upper(),dataset, num_epochs, aug_strategy, train_path, test_path)\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["User Model VGG16\n","Expected Epochs is 70\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 19s 0us/step\n","553476096/553467096 [==============================] - 19s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","logit (Dense)                (None, 12)                49164     \n","=================================================================\n","Total params: 134,309,708\n","Trainable params: 134,309,708\n","Non-trainable params: 0\n","_________________________________________________________________\n","Found 4655 images belonging to 12 classes.\n","Found 175 images belonging to 12 classes.\n","Epoch 1/70\n","  8/146 [>.............................] - ETA: 40:41 - loss: 2.8193 - accuracy: 0.0377"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTtM7taK0w2R","executionInfo":{"elapsed":310,"status":"error","timestamp":1623068420795,"user":{"displayName":"Susan Potters","photoUrl":"","userId":"03730811778263408439"},"user_tz":-120},"outputId":"755d8f48-5cbd-44e7-ad4c-056808dc3771"},"source":["# %load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","\n","%tensorboard --logdir logs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["UsageError: Line magic function `%tensorboard` not found.\n"],"name":"stderr"}]}]}